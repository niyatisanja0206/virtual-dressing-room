# ğŸ‘— Virtual Dressing Room System Using Computer Vision and Deep Learning

This repository implements a high-resolution **2D virtual try-on system** that allows users to try garments virtually using just two input images â€” a photo of a person and a clothing item. The pipeline is built upon the VITON-HD architecture with enhanced human parsing using the CIHP_PGN model.

---

## âœ¨ Project Highlights

- Realistic 2D garment fitting using **pose estimation**, **semantic segmentation**, and **image warping**.
- Uses **OpenPose** for skeletal landmark detection.
- Employs a **PGN-based segmentation model** for precise body part parsing.
- Supports **high-resolution try-on (1024x768)** using ALIAS and SPADE-based deep image synthesis.
- No 3D data or multi-view input required â€” works with just 2 front-view images.

---
## ğŸ“¸ Output Screenshots

Here are a few sample results generated by the virtual dressing room system:
![image](https://github.com/user-attachments/assets/206cec04-34b4-4ae4-9efb-d24c2788c510)

---
## ğŸ“‚ Project Structure

```
â”œâ”€â”€ checkpoints/               # Downloaded model checkpoints (place here)
â”œâ”€â”€ inputset/
â”‚   â””â”€â”€ test/
â”‚       â”œâ”€â”€ cloth/
â”‚       â”œâ”€â”€ cloth-mask/
â”‚       â”œâ”€â”€ image/
â”‚       â”œâ”€â”€ image-parse/
â”‚       â”œâ”€â”€ openpose-img/
â”‚       â””â”€â”€ openpose-json/
â”œâ”€â”€ results/                   # Output results after running test
â”œâ”€â”€ input.py                   # Preprocessing script for a single pair (image + cloth)
â”œâ”€â”€ test.py                    # Inference script (try-on)
â”œâ”€â”€ requirements.txt           # Python dependencies (pip)
â”œâ”€â”€ environment.yml            # Conda environment (recommended)
â””â”€â”€ README.md
```

---

## âš™ï¸ Setup Instructions

### 1. **Clone the repository**

```bash
git clone https://github.com/yourusername/virtual-dressing-room.git
cd virtual-dressing-room
```

### 2. **Install dependencies**

Using Conda (recommended):

```bash
conda env create -f environment.yml
conda activate viton-env
```

### 3. **Download Checkpoints**

Download the following models and place them in the `checkpoints/` directory:

- **CIHP_PGN** for human parsing  
  _(Place inside `checkpoints/CIHP_PGN`)_

- **GMM, SegGenerator, and ALIASGenerator** weights from the official VITON-HD release  
  _(Place inside `checkpoints/`)_

- **OpenPose** for pose detection and keypoints  
  _(Place inside `openpose/models/pose/coco/`)_

---

## ğŸ§ª Inference on Custom Inputs 

### ğŸ–¼ 1. Prepare Your Inputs

Youâ€™ll need two front-facing images:

- A person image (e.g., `person.jpg`)
- A cloth image (e.g., `cloth.png`)

Place them anywhere on your system.

### ğŸ” 2. Run Preprocessing (input.py)

```bash
python input.py
```

When prompted, enter the full paths to your image and cloth:

```txt
ğŸ‘¤ Enter the full path to the person image: D:/path/to/person.jpg
ğŸ‘• Enter the full path to the cloth image: D:/path/to/cloth.png
```

This step will:

- Copy and format the input images  
- Run OpenPose for pose keypoints  
- Generate the cloth mask  
- Generate the person segmentation using PGN  
- Write the required `test_pairs.txt`

---

### ğŸ¨ 3. Run Virtual Try-On (test.py)

```bash
python test.py \
  --name test_output \
  --dataset_dir ./inputset \
  --dataset_mode test \
  --dataset_list test_pairs.txt \
  --checkpoint_dir ./checkpoints \
  --save_dir ./results
```

Output images will be saved to the `results/` folder.

---

## ğŸ“– Methodology (Summary)

This project is based on VITON-HD with key improvements:

- **PGN Segmentation**: Accurate parsing of body regions (head, torso, arms)
- **OpenPose**: Skeleton-based pose detection for warping alignment
- **TPS Warping**: Flexible garment transformation using Geometric Matching Module (GMM)
- **ALIAS + SPADE Generator**: Photorealistic final image synthesis using adversarial training with multiple loss functions (L1, VGG, GAN)

For complete details, please refer to the attached research paper in the repository.

---

## ğŸ“ Authors

- Niyati Raiyani(niyati34)
- Yukta Mahedu(yukta65)
- Niyati Sanja(niyatisanja0206)
- Dhruvi Topiya(dtecktrack)

---

## ğŸ“ License

MIT License (or specify your chosen license).

---

## ğŸ“Œ Acknowledgment

Special thanks to the authors of VITON-HD and the PGN parsing model.
